{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185dc5ff-be5c-41f8-9f84-d9c1bc0a9ced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:27:40.353443Z",
     "iopub.status.busy": "2025-11-07T07:27:40.352443Z",
     "iopub.status.idle": "2025-11-07T07:27:40.388262Z",
     "shell.execute_reply": "2025-11-07T07:27:40.383680Z",
     "shell.execute_reply.started": "2025-11-07T07:27:40.353443Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "047a8159-ddcc-491d-859a-053a4e2a8d5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:32:40.380458Z",
     "iopub.status.busy": "2025-11-07T07:32:40.379436Z",
     "iopub.status.idle": "2025-11-07T07:32:40.388833Z",
     "shell.execute_reply": "2025-11-07T07:32:40.387262Z",
     "shell.execute_reply.started": "2025-11-07T07:32:40.380458Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.eazydiner.com/restaurants?city=hyderabad&location=hyderabad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96904817-1d9e-4cc1-9488-ed5d6a043f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:32:42.089598Z",
     "iopub.status.busy": "2025-11-07T07:32:42.088577Z",
     "iopub.status.idle": "2025-11-07T07:32:42.096088Z",
     "shell.execute_reply": "2025-11-07T07:32:42.094912Z",
     "shell.execute_reply.started": "2025-11-07T07:32:42.089598Z"
    }
   },
   "outputs": [],
   "source": [
    "#Headers for request\n",
    "Headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36 Edg/142.0.0.0','Accept-Language':'en-US ,en;q=0.5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "858580b5-13c4-4042-b1d7-cb6f90741fea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:32:43.022646Z",
     "iopub.status.busy": "2025-11-07T07:32:43.021635Z",
     "iopub.status.idle": "2025-11-07T07:32:44.040256Z",
     "shell.execute_reply": "2025-11-07T07:32:44.039751Z",
     "shell.execute_reply.started": "2025-11-07T07:32:43.022646Z"
    }
   },
   "outputs": [],
   "source": [
    "#HTTP Request\n",
    "webpage = requests.get(url, headers=Headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22f881b3-3585-4aea-bb50-73515057559f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:32:45.209995Z",
     "iopub.status.busy": "2025-11-07T07:32:45.208970Z",
     "iopub.status.idle": "2025-11-07T07:32:45.217410Z",
     "shell.execute_reply": "2025-11-07T07:32:45.216395Z",
     "shell.execute_reply.started": "2025-11-07T07:32:45.209995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3881805-d53d-4f03-a7f3-523205fca894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:34:43.049381Z",
     "iopub.status.busy": "2025-11-07T07:34:43.049381Z",
     "iopub.status.idle": "2025-11-07T07:34:43.072880Z",
     "shell.execute_reply": "2025-11-07T07:34:43.071370Z",
     "shell.execute_reply.started": "2025-11-07T07:34:43.049381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(webpage.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27eff8b0-6288-4eb3-97de-90466526e503",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T07:36:16.106682Z",
     "iopub.status.busy": "2025-11-07T07:36:16.106682Z",
     "iopub.status.idle": "2025-11-07T07:36:16.195787Z",
     "shell.execute_reply": "2025-11-07T07:36:16.195787Z",
     "shell.execute_reply.started": "2025-11-07T07:36:16.106682Z"
    }
   },
   "outputs": [],
   "source": [
    "#Soup Object cotaiing all data \n",
    "soup = BeautifulSoup(webpage.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80f2b785-6669-4064-a560-267ba3b31121",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:07:13.311711Z",
     "iopub.status.busy": "2025-11-07T08:07:13.311711Z",
     "iopub.status.idle": "2025-11-07T08:07:13.323386Z",
     "shell.execute_reply": "2025-11-07T08:07:13.322373Z",
     "shell.execute_reply.started": "2025-11-07T08:07:13.311711Z"
    }
   },
   "outputs": [],
   "source": [
    "#Fetch links as list of tag objects\n",
    "links = soup.find_all(\"a\",attrs={'class':'ellipsis listing_res_name__uVIN8'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36184a51-a693-4c7e-8eda-ef437dc6e5d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:07:16.580663Z",
     "iopub.status.busy": "2025-11-07T08:07:16.579660Z",
     "iopub.status.idle": "2025-11-07T08:07:16.586821Z",
     "shell.execute_reply": "2025-11-07T08:07:16.586821Z",
     "shell.execute_reply.started": "2025-11-07T08:07:16.580663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/sixty-three-degrees-gachibowli-hyderabad-692677?deal_types[]=postpaid\">63 Degree Modern Regional Buffet</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/golconda-pavilion-itc-kohenur-hyderabad-657734?deal_types[]=postpaid\">Golconda Pavilion</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/exotica-banjara-hills-hyderabad-648799?deal_types[]=postpaid\">Exotica</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/forefathers-road-no-45-jubilee-hills-hyderabad-696918?deal_types[]=postpaid\">Forefathers</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/the-ofen-banjara-hills-hyderabad-648800?deal_types[]=postpaid\">The Ofen</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/one8-commune-hitech-city-hyderabad-695370?deal_types[]=postpaid\">one8 Commune</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/pizza-zone-habsiguda-hyderabad-696304?deal_types[]=postpaid\">Pizza Zone</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/aster-cafe-kitchen-road-no-12-banjara-hills-hyderabad-695065?deal_types[]=postpaid\">Aster Cafe &amp; Kitchen</a>,\n",
       " <a class=\"ellipsis listing_res_name__uVIN8\" href=\"https://www.eazydiner.com/hyderabad/fuel-cafe-banjara-hills-hyderabad-684079?deal_types[]=postpaid\">Fuel Cafe</a>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a61a6933-894d-40fd-ba44-8d217768a12d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:13:47.541426Z",
     "iopub.status.busy": "2025-11-07T08:13:47.540426Z",
     "iopub.status.idle": "2025-11-07T08:13:47.546891Z",
     "shell.execute_reply": "2025-11-07T08:13:47.545346Z",
     "shell.execute_reply.started": "2025-11-07T08:13:47.541426Z"
    }
   },
   "outputs": [],
   "source": [
    "link = links[0].get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac796a03-80d6-4e3c-8c83-bd6434b67f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:17:30.550581Z",
     "iopub.status.busy": "2025-11-07T08:17:30.550581Z",
     "iopub.status.idle": "2025-11-07T08:17:30.555865Z",
     "shell.execute_reply": "2025-11-07T08:17:30.554844Z",
     "shell.execute_reply.started": "2025-11-07T08:17:30.550581Z"
    }
   },
   "outputs": [],
   "source": [
    "product_link = \" \" + link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83665ec4-dfd0-4d56-8dcd-3da382b3c5af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:17:32.833092Z",
     "iopub.status.busy": "2025-11-07T08:17:32.831956Z",
     "iopub.status.idle": "2025-11-07T08:17:32.839691Z",
     "shell.execute_reply": "2025-11-07T08:17:32.838681Z",
     "shell.execute_reply.started": "2025-11-07T08:17:32.833092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' https://www.eazydiner.com/hyderabad/sixty-three-degrees-gachibowli-hyderabad-692677?deal_types[]=postpaid'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a26fe993-dcb2-4fd6-83cb-f7f2ddb8a4b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:20:00.316901Z",
     "iopub.status.busy": "2025-11-07T08:20:00.316901Z",
     "iopub.status.idle": "2025-11-07T08:20:00.829956Z",
     "shell.execute_reply": "2025-11-07T08:20:00.829956Z",
     "shell.execute_reply.started": "2025-11-07T08:20:00.316901Z"
    }
   },
   "outputs": [],
   "source": [
    "new_webpage = requests.get(product_link, headers=Headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1409dab7-0d69-482b-9a59-ee64d0a9ceb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:20:05.221415Z",
     "iopub.status.busy": "2025-11-07T08:20:05.220410Z",
     "iopub.status.idle": "2025-11-07T08:20:05.229217Z",
     "shell.execute_reply": "2025-11-07T08:20:05.227647Z",
     "shell.execute_reply.started": "2025-11-07T08:20:05.221415Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7338e060-7f5a-45ee-93c1-d982715ff27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T08:21:14.784483Z",
     "iopub.status.busy": "2025-11-07T08:21:14.783482Z",
     "iopub.status.idle": "2025-11-07T08:21:14.843879Z",
     "shell.execute_reply": "2025-11-07T08:21:14.842862Z",
     "shell.execute_reply.started": "2025-11-07T08:21:14.784483Z"
    }
   },
   "outputs": [],
   "source": [
    "new_soup = BeautifulSoup(new_webpage.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20e2fb9f-06e8-4559-b97b-76a954e201ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:29:32.769140Z",
     "iopub.status.busy": "2025-11-07T09:29:32.768134Z",
     "iopub.status.idle": "2025-11-07T09:29:33.318271Z",
     "shell.execute_reply": "2025-11-07T09:29:33.315265Z",
     "shell.execute_reply.started": "2025-11-07T09:29:32.769140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "✅ Extracted 0 restaurants.\n",
      "✅ Data saved to eazydiner_hyderabad.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Hyderabad Scraper (Next.js JSON Endpoint)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Actual data endpoint\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "# Fetch JSON data\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "else:\n",
    "    print(f\"⚠️ Failed to fetch data. Status code: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "# ==============================================================\n",
    "# Extract restaurants from the JSON structure\n",
    "# ==============================================================\n",
    "\n",
    "# The JSON hierarchy can vary; let's locate where restaurant info is stored\n",
    "page_props = data.get(\"pageProps\", {})\n",
    "restaurant_data = (\n",
    "    page_props.get(\"data\", {}).get(\"restaurant_data\")\n",
    "    or page_props.get(\"restaurants\")\n",
    "    or []\n",
    ")\n",
    "\n",
    "# Parse results\n",
    "records = []\n",
    "for rest in restaurant_data:\n",
    "    info = rest.get(\"info\", {})\n",
    "    records.append({\n",
    "        \"Restaurant Name\": info.get(\"name\"),\n",
    "        \"Cuisine\": \", \".join([c.get(\"name\") for c in info.get(\"cuisine\", [])]) if info.get(\"cuisine\") else None,\n",
    "        \"Location\": info.get(\"locality\", {}).get(\"name\"),\n",
    "        \"Cost for Two\": info.get(\"costText\", {}).get(\"text\"),\n",
    "        \"Rating\": info.get(\"rating\", {}).get(\"aggregate_rating\"),\n",
    "        \"Votes\": info.get(\"rating\", {}).get(\"votes\"),\n",
    "        \"URL\": info.get(\"url\")\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n",
    "print(f\"✅ Extracted {len(df)} restaurants.\")\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"eazydiner_hyderabad.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_hyderabad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f3f627e-d578-4cb8-91e0-53e3adaccce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:30:18.359936Z",
     "iopub.status.busy": "2025-11-07T09:30:18.359936Z",
     "iopub.status.idle": "2025-11-07T09:30:19.724357Z",
     "shell.execute_reply": "2025-11-07T09:30:19.723349Z",
     "shell.execute_reply.started": "2025-11-07T09:30:18.359936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- pageProps: dict\n",
      "  - data: dict\n",
      "    - responseInfo: dict\n",
      "    - data: dict\n",
      "    - meta: dict\n",
      "    - customer_bookings: list\n",
      "  - userLocation: dict\n",
      "    - name: str\n",
      "    - code: str\n",
      "    - city_code: str\n",
      "    - city_name: str\n",
      "    - lat: float\n",
      "    - long: float\n",
      "    - city_id: int\n",
      "    - country_id: int\n",
      "    - group_id: int\n",
      "  - token: str\n",
      "  - isDesktop: bool\n",
      "  - pageName: str\n",
      "  - isCityPage: int\n",
      "  - metaData: dict\n",
      "    - title: str\n",
      "    - description: str\n",
      "    - jsonSchema: list\n",
      "  - footerSeo: dict\n",
      "    - responseInfo: dict\n",
      "    - data: dict\n",
      "  - cityData: dict\n",
      "    - responseInfo: dict\n",
      "    - data: dict\n",
      "    - meta_title: str\n",
      "    - meta_description: str\n",
      "  - userDetails: NoneType\n",
      "  - domain: str\n",
      "  - pageView: str\n",
      "- __N_SSP: bool\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "data = r.json()\n",
    "\n",
    "# Pretty print the structure (first 2 levels only)\n",
    "def explore_json(d, indent=0):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            print(\"  \" * indent + f\"- {k}: {type(v).__name__}\")\n",
    "            if indent < 2:\n",
    "                explore_json(v, indent + 1)\n",
    "    elif isinstance(d, list) and len(d) > 0:\n",
    "        print(\"  \" * indent + f\"[0]: {type(d[0]).__name__}\")\n",
    "        if indent < 2:\n",
    "            explore_json(d[0], indent + 1)\n",
    "\n",
    "explore_json(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ca8601f-8677-454d-833e-2306c22eecc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:31:22.158446Z",
     "iopub.status.busy": "2025-11-07T09:31:22.157434Z",
     "iopub.status.idle": "2025-11-07T09:31:22.806162Z",
     "shell.execute_reply": "2025-11-07T09:31:22.804218Z",
     "shell.execute_reply.started": "2025-11-07T09:31:22.158446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 4 restaurants in JSON.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m records \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m restaurants:\n\u001b[1;32m---> 37\u001b[0m     name \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     location \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocality\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocality\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     cuisines \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([c\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuisine\u001b[39m\u001b[38;5;124m\"\u001b[39m, [])]) \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuisine\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Hyderabad Scraper (Confirmed JSON Path)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Actual JSON endpoint (you found it!)\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code != 200:\n",
    "    print(f\"⚠️ Failed to fetch data, status code: {response.status_code}\")\n",
    "    exit()\n",
    "\n",
    "json_data = response.json()\n",
    "\n",
    "# Navigate to the correct nested path\n",
    "restaurants = json_data.get(\"pageProps\", {}).get(\"data\", {}).get(\"data\", [])\n",
    "\n",
    "if not restaurants:\n",
    "    print(\"⚠️ No restaurants found — JSON path may differ slightly.\")\n",
    "else:\n",
    "    print(f\"✅ Found {len(restaurants)} restaurants in JSON.\")\n",
    "\n",
    "# Parse restaurant details\n",
    "records = []\n",
    "for r in restaurants:\n",
    "    name = r.get(\"name\")\n",
    "    location = r.get(\"locality\", {}).get(\"name\") if isinstance(r.get(\"locality\"), dict) else None\n",
    "    cuisines = \", \".join([c.get(\"name\") for c in r.get(\"cuisine\", [])]) if r.get(\"cuisine\") else None\n",
    "    rating = r.get(\"rating\", {}).get(\"aggregate_rating\") if isinstance(r.get(\"rating\"), dict) else None\n",
    "    cost = r.get(\"costText\", {}).get(\"text\") if isinstance(r.get(\"costText\"), dict) else None\n",
    "    votes = r.get(\"rating\", {}).get(\"votes\") if isinstance(r.get(\"rating\"), dict) else None\n",
    "    url_rest = r.get(\"url\")\n",
    "\n",
    "    records.append({\n",
    "        \"Restaurant Name\": name,\n",
    "        \"Cuisine\": cuisines,\n",
    "        \"Location\": location,\n",
    "        \"Cost for Two\": cost,\n",
    "        \"Rating\": rating,\n",
    "        \"Votes\": votes,\n",
    "        \"URL\": url_rest\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and save\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n",
    "print(f\"✅ Extracted {len(df)} restaurants.\")\n",
    "df.to_csv(\"eazydiner_hyderabad.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_hyderabad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac9c2581-0ce4-4de8-8b9d-33cdcbcd283f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:32:12.098919Z",
     "iopub.status.busy": "2025-11-07T09:32:12.098919Z",
     "iopub.status.idle": "2025-11-07T09:32:12.722033Z",
     "shell.execute_reply": "2025-11-07T09:32:12.719745Z",
     "shell.execute_reply.started": "2025-11-07T09:32:12.098919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m restaurants \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpageProps\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal items:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(restaurants))\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of first item:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(restaurants[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(restaurants[\u001b[38;5;241m0\u001b[39m], indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "data = requests.get(url, headers=headers).json()\n",
    "\n",
    "restaurants = data[\"pageProps\"][\"data\"][\"data\"]\n",
    "\n",
    "print(\"Total items:\", len(restaurants))\n",
    "print(\"Type of first item:\", type(restaurants[0]))\n",
    "print(json.dumps(restaurants[0], indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54cb8486-28f6-4919-bf65-b64ff5004916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:32:45.193663Z",
     "iopub.status.busy": "2025-11-07T09:32:45.192610Z",
     "iopub.status.idle": "2025-11-07T09:32:46.137945Z",
     "shell.execute_reply": "2025-11-07T09:32:46.134917Z",
     "shell.execute_reply.started": "2025-11-07T09:32:45.193663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewTitle → str\n",
      "view → str\n",
      "banners → list\n",
      "buckets → dict\n",
      "\n",
      "Sample preview of a nested key (choose one that looks relevant):\n",
      "First key: viewTitle\n",
      "\"cityhome\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "data = requests.get(url, headers=headers).json()\n",
    "\n",
    "level2 = data[\"pageProps\"][\"data\"][\"data\"]\n",
    "\n",
    "# print all keys and types under this dictionary\n",
    "for k, v in level2.items():\n",
    "    print(f\"{k} → {type(v).__name__}\")\n",
    "\n",
    "# optional: print a preview of one key’s value (the one that looks like it might contain restaurants)\n",
    "print(\"\\nSample preview of a nested key (choose one that looks relevant):\")\n",
    "first_key = list(level2.keys())[0]\n",
    "print(f\"First key: {first_key}\")\n",
    "print(json.dumps(level2[first_key], indent=2)[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b39bda2-cb37-4a8a-a6d5-08cc1a3167ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:33:14.721217Z",
     "iopub.status.busy": "2025-11-07T09:33:14.720187Z",
     "iopub.status.idle": "2025-11-07T09:33:15.596797Z",
     "shell.execute_reply": "2025-11-07T09:33:15.595783Z",
     "shell.execute_reply.started": "2025-11-07T09:33:14.720187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket keys:\n",
      "- main_meal_bucket\n",
      "- box-small-new\n",
      "- popular_restaurants\n",
      "- locations\n",
      "- cuisines\n",
      "- trends\n",
      "- partners\n",
      "\n",
      "Preview for first bucket: main_meal_bucket\n",
      "{\n",
      "  \"title\": \"\",\n",
      "  \"sub_title\": \"\",\n",
      "  \"items\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "data = requests.get(url, headers=headers).json()\n",
    "\n",
    "buckets = data[\"pageProps\"][\"data\"][\"data\"][\"buckets\"]\n",
    "\n",
    "# Print all bucket keys\n",
    "print(\"Bucket keys:\")\n",
    "for k in buckets.keys():\n",
    "    print(\"-\", k)\n",
    "\n",
    "# Show preview of the first bucket (structure of restaurant data)\n",
    "first_key = list(buckets.keys())[0]\n",
    "print(f\"\\nPreview for first bucket: {first_key}\")\n",
    "print(json.dumps(buckets[first_key], indent=2)[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7808b69-787c-4416-bc1e-1daf161152cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:33:41.262171Z",
     "iopub.status.busy": "2025-11-07T09:33:41.261028Z",
     "iopub.status.idle": "2025-11-07T09:33:41.888401Z",
     "shell.execute_reply": "2025-11-07T09:33:41.887274Z",
     "shell.execute_reply.started": "2025-11-07T09:33:41.262171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in popular_restaurants bucket: dict_keys(['title', 'sub_title', 'sub_title_link', 'items'])\n",
      "\n",
      "Total items: 6\n",
      "{\n",
      "  \"id\": 684079,\n",
      "  \"action_url\": \"hyderabad/fuel-cafe-banjara-hills-hyderabad-684079\",\n",
      "  \"image\": \"https://dt4l9bx31tioh.cloudfront.net/eazymedia/restaurant/684079/restaurant820220714065006.jpg\",\n",
      "  \"rating\": \"4.0\",\n",
      "  \"res_name\": \"Fuel Cafe\",\n",
      "  \"location\": \"Banjara Hills, Hyderabad\",\n",
      "  \"deal_text\": \"15% Off + 25% Off\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "data = requests.get(url, headers=headers).json()\n",
    "\n",
    "popular = data[\"pageProps\"][\"data\"][\"data\"][\"buckets\"][\"popular_restaurants\"]\n",
    "\n",
    "print(\"Keys in popular_restaurants bucket:\", popular.keys())\n",
    "\n",
    "# Print preview of the items list\n",
    "if \"items\" in popular:\n",
    "    print(f\"\\nTotal items: {len(popular['items'])}\")\n",
    "    if len(popular[\"items\"]) > 0:\n",
    "        print(json.dumps(popular[\"items\"][0], indent=2)[:2000])\n",
    "    else:\n",
    "        print(\"⚠️ No items found inside 'popular_restaurants'.\")\n",
    "else:\n",
    "    print(\"⚠️ No 'items' key inside popular_restaurants.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e7fb37b-7711-429e-8105-b18a79c44485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:35:03.270799Z",
     "iopub.status.busy": "2025-11-07T09:35:03.270799Z",
     "iopub.status.idle": "2025-11-07T09:35:03.878271Z",
     "shell.execute_reply": "2025-11-07T09:35:03.876751Z",
     "shell.execute_reply.started": "2025-11-07T09:35:03.270799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Restaurant Name                               Location Rating  \\\n",
      "0             Fuel Cafe               Banjara Hills, Hyderabad    4.0   \n",
      "1  Aster Cafe & Kitchen  Road No. 12, Banjara Hills, Hyderabad    4.0   \n",
      "2             7 Sisters               Banjara Hills, Hyderabad    4.4   \n",
      "3       La Pino'z Pizza  Road No. 12, Banjara Hills, Hyderabad    5.0   \n",
      "4           Mazuri Cafe               Banjara Hills, Hyderabad    4.0   \n",
      "5               Vasaara               Banjara Hills, Hyderabad    4.0   \n",
      "\n",
      "                Deal                                          Image URL  \\\n",
      "0  15% Off + 25% Off  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "1  10% Off + 25% Off  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "2  30% Off + 25% Off  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "3  10% Off + 25% Off  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "4  30% Off + 25% Off  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "5  30% Off + 25% Off  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "\n",
      "                                      Restaurant URL  \n",
      "0  https://www.eazydiner.com/hyderabad/fuel-cafe-...  \n",
      "1  https://www.eazydiner.com/hyderabad/aster-cafe...  \n",
      "2  https://www.eazydiner.com/hyderabad/7-sisters-...  \n",
      "3  https://www.eazydiner.com/hyderabad/la-pinoz-p...  \n",
      "4  https://www.eazydiner.com/hyderabad/mazuri-caf...  \n",
      "5  https://www.eazydiner.com/hyderabad/vasaara-ba...  \n",
      "\n",
      "✅ Extracted 6 restaurants.\n",
      "✅ Data saved to eazydiner_hyderabad.csv\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Hyderabad Scraper (Confirmed Working Version)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# JSON endpoint for Hyderabad\n",
    "url = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en/hyderabad.json\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "# Fetch JSON data\n",
    "response = requests.get(url, headers=headers)\n",
    "if response.status_code != 200:\n",
    "    print(f\"⚠️ Failed to fetch data (Status code: {response.status_code})\")\n",
    "    exit()\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "# Navigate to restaurant list\n",
    "restaurants = (\n",
    "    data.get(\"pageProps\", {})\n",
    "        .get(\"data\", {})\n",
    "        .get(\"data\", {})\n",
    "        .get(\"buckets\", {})\n",
    "        .get(\"popular_restaurants\", {})\n",
    "        .get(\"items\", [])\n",
    ")\n",
    "\n",
    "# Parse restaurant info\n",
    "records = []\n",
    "for rest in restaurants:\n",
    "    name = rest.get(\"res_name\")\n",
    "    location = rest.get(\"location\")\n",
    "    rating = rest.get(\"rating\")\n",
    "    deal = rest.get(\"deal_text\")\n",
    "    img = rest.get(\"image\")\n",
    "    url_rest = (\n",
    "        \"https://www.eazydiner.com/\" + rest.get(\"action_url\", \"\").lstrip(\"/\")\n",
    "        if rest.get(\"action_url\")\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    records.append({\n",
    "        \"Restaurant Name\": name,\n",
    "        \"Location\": location,\n",
    "        \"Rating\": rating,\n",
    "        \"Deal\": deal,\n",
    "        \"Image URL\": img,\n",
    "        \"Restaurant URL\": url_rest\n",
    "    })\n",
    "\n",
    "# Save results\n",
    "df = pd.DataFrame(records)\n",
    "print(df)\n",
    "print(f\"\\n✅ Extracted {len(df)} restaurants.\")\n",
    "df.to_csv(\"eazydiner_hyderabad.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_hyderabad.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ba746d4-b9ce-4359-8e12-90ea060ba003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:36:46.287851Z",
     "iopub.status.busy": "2025-11-07T09:36:46.287851Z",
     "iopub.status.idle": "2025-11-07T09:36:51.556281Z",
     "shell.execute_reply": "2025-11-07T09:36:51.555774Z",
     "shell.execute_reply.started": "2025-11-07T09:36:46.287851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 3 cities on EazyDiner.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  33%|██████████████████████▎                                            | 1/3 [00:01<00:02,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping header (status 404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  67%|████████████████████████████████████████████▋                      | 2/3 [00:03<00:01,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping popular_cities (status 404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities: 100%|███████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Skipping unpopular_cities (status 404)\n",
      "\n",
      "✅ Extracted total 0 restaurants across 3 cities.\n",
      "✅ Data saved to eazydiner_all_cities.csv\n",
      "\n",
      "Sample:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Multi-City Restaurant Scraper (Fixed Version)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas tqdm\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en\"\n",
    "CITIES_API = \"https://force.eazydiner.com/web/all-cities\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Fetch all cities from EazyDiner\n",
    "# --------------------------------------------------------------\n",
    "resp = requests.get(CITIES_API, headers=headers)\n",
    "if resp.status_code != 200:\n",
    "    print(\"⚠️ Failed to fetch city list.\")\n",
    "    exit()\n",
    "\n",
    "cities_data = resp.json().get(\"data\", [])\n",
    "\n",
    "# Handle both possible formats: list of dicts or list of strings\n",
    "cities = []\n",
    "for c in cities_data:\n",
    "    if isinstance(c, dict):\n",
    "        code = c.get(\"code\")\n",
    "        if code:\n",
    "            cities.append(code)\n",
    "    elif isinstance(c, str):\n",
    "        cities.append(c.lower().strip())\n",
    "\n",
    "print(f\"✅ Found {len(cities)} cities on EazyDiner.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Loop through each city and collect restaurants\n",
    "# --------------------------------------------------------------\n",
    "all_restaurants = []\n",
    "\n",
    "for city in tqdm(cities, desc=\"Scraping Cities\"):\n",
    "    city_url = f\"{BASE_URL}/{city}.json\"\n",
    "\n",
    "    try:\n",
    "        res = requests.get(city_url, headers=headers, timeout=20)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"⚠️ Skipping {city} (status {res.status_code})\")\n",
    "            continue\n",
    "\n",
    "        data = res.json()\n",
    "        restaurants = (\n",
    "            data.get(\"pageProps\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"buckets\", {})\n",
    "                .get(\"popular_restaurants\", {})\n",
    "                .get(\"items\", [])\n",
    "        )\n",
    "\n",
    "        if not restaurants:\n",
    "            continue\n",
    "\n",
    "        for rest in restaurants:\n",
    "            all_restaurants.append({\n",
    "                \"City\": city,\n",
    "                \"Restaurant Name\": rest.get(\"res_name\"),\n",
    "                \"Location\": rest.get(\"location\"),\n",
    "                \"Rating\": rest.get(\"rating\"),\n",
    "                \"Deal\": rest.get(\"deal_text\"),\n",
    "                \"Image URL\": rest.get(\"image\"),\n",
    "                \"Restaurant URL\": (\n",
    "                    \"https://www.eazydiner.com/\" + rest.get(\"action_url\", \"\").lstrip(\"/\")\n",
    "                    if rest.get(\"action_url\") else None\n",
    "                )\n",
    "            })\n",
    "\n",
    "        # Be polite — avoid overloading the server\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {city}: {e}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Save all data to CSV\n",
    "# --------------------------------------------------------------\n",
    "df = pd.DataFrame(all_restaurants)\n",
    "print(f\"\\n✅ Extracted total {len(df)} restaurants across {len(cities)} cities.\")\n",
    "\n",
    "df.to_csv(\"eazydiner_all_cities.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_all_cities.csv\")\n",
    "\n",
    "# Optional: Display sample output\n",
    "print(\"\\nSample:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a35687f8-ef12-45c3-94f5-e871827901ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:37:38.618143Z",
     "iopub.status.busy": "2025-11-07T09:37:38.618143Z",
     "iopub.status.idle": "2025-11-07T09:37:39.260528Z",
     "shell.execute_reply": "2025-11-07T09:37:39.258522Z",
     "shell.execute_reply.started": "2025-11-07T09:37:38.618143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 0 restaurant cities on EazyDiner.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Extracted total 0 restaurants across 0 cities.\n",
      "✅ Data saved to eazydiner_all_cities.csv\n",
      "\n",
      "Sample:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Multi-City Scraper (Full City Extraction)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas tqdm\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en\"\n",
    "CITIES_API = \"https://force.eazydiner.com/web/all-cities\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Fetch all cities from EazyDiner\n",
    "# --------------------------------------------------------------\n",
    "resp = requests.get(CITIES_API, headers=headers)\n",
    "if resp.status_code != 200:\n",
    "    print(\"⚠️ Failed to fetch city list.\")\n",
    "    exit()\n",
    "\n",
    "cities_raw = resp.json()\n",
    "\n",
    "# Extract city codes properly\n",
    "city_codes = []\n",
    "for section in [\"popular_cities\", \"unpopular_cities\"]:\n",
    "    section_data = cities_raw.get(section, {}).get(\"cities\", [])\n",
    "    for city in section_data:\n",
    "        code = city.get(\"code\")\n",
    "        if code:\n",
    "            city_codes.append(code.lower())\n",
    "\n",
    "print(f\"✅ Found {len(city_codes)} restaurant cities on EazyDiner.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Loop through each city and collect restaurants\n",
    "# --------------------------------------------------------------\n",
    "all_restaurants = []\n",
    "\n",
    "for city in tqdm(city_codes, desc=\"Scraping Cities\"):\n",
    "    city_url = f\"{BASE_URL}/{city}.json\"\n",
    "\n",
    "    try:\n",
    "        res = requests.get(city_url, headers=headers, timeout=20)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"⚠️ Skipping {city} (status {res.status_code})\")\n",
    "            continue\n",
    "\n",
    "        data = res.json()\n",
    "        restaurants = (\n",
    "            data.get(\"pageProps\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"buckets\", {})\n",
    "                .get(\"popular_restaurants\", {})\n",
    "                .get(\"items\", [])\n",
    "        )\n",
    "\n",
    "        if not restaurants:\n",
    "            continue\n",
    "\n",
    "        for rest in restaurants:\n",
    "            all_restaurants.append({\n",
    "                \"City\": city,\n",
    "                \"Restaurant Name\": rest.get(\"res_name\"),\n",
    "                \"Location\": rest.get(\"location\"),\n",
    "                \"Rating\": rest.get(\"rating\"),\n",
    "                \"Deal\": rest.get(\"deal_text\"),\n",
    "                \"Image URL\": rest.get(\"image\"),\n",
    "                \"Restaurant URL\": (\n",
    "                    \"https://www.eazydiner.com/\" + rest.get(\"action_url\", \"\").lstrip(\"/\")\n",
    "                    if rest.get(\"action_url\") else None\n",
    "                )\n",
    "            })\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {city}: {e}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Save all data to CSV\n",
    "# --------------------------------------------------------------\n",
    "df = pd.DataFrame(all_restaurants)\n",
    "print(f\"\\n✅ Extracted total {len(df)} restaurants across {len(city_codes)} cities.\")\n",
    "df.to_csv(\"eazydiner_all_cities.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_all_cities.csv\")\n",
    "\n",
    "print(\"\\nSample:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acf9ba77-7470-40cc-aee6-1b40580b203a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:38:35.420642Z",
     "iopub.status.busy": "2025-11-07T09:38:35.419165Z",
     "iopub.status.idle": "2025-11-07T09:38:35.649559Z",
     "shell.execute_reply": "2025-11-07T09:38:35.648262Z",
     "shell.execute_reply.started": "2025-11-07T09:38:35.420642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: ['data', 'meta_title', 'meta_description']\n",
      "\n",
      "Sample (first 500 chars):\n",
      "\n",
      "{\n",
      "  \"data\": {\n",
      "    \"header\": \"Book a Table in 338 cities in India and Dubai\",\n",
      "    \"popular_cities\": [\n",
      "      {\n",
      "        \"url\": \"/delhi-ncr\",\n",
      "        \"image\": \"https://dt4l9bx31tioh.cloudfront.net/eazymedia/cities/delhi-ncr-22.png\",\n",
      "        \"name\": \"Delhi NCR\",\n",
      "        \"code\": \"delhi-ncr\",\n",
      "        \"restaurants_count\": 17035\n",
      "      },\n",
      "      {\n",
      "        \"url\": \"/mumbai\",\n",
      "        \"image\": \"https://dt4l9bx31tioh.cloudfront.net/eazymedia/cities/mumbai-22.png\",\n",
      "        \"name\": \"Mumbai\",\n",
      "        \"code\": \"mumb\n"
     ]
    }
   ],
   "source": [
    "import requests, json\n",
    "\n",
    "url = \"https://force.eazydiner.com/web/all-cities\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "data = r.json()\n",
    "\n",
    "print(\"Top-level keys:\", list(data.keys()))\n",
    "print(\"\\nSample (first 500 chars):\\n\")\n",
    "print(json.dumps(data, indent=2)[:500])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e5729a39-897b-4d54-b8a9-7e42842225c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:39:06.765020Z",
     "iopub.status.busy": "2025-11-07T09:39:06.763956Z",
     "iopub.status.idle": "2025-11-07T09:40:38.791752Z",
     "shell.execute_reply": "2025-11-07T09:40:38.790187Z",
     "shell.execute_reply.started": "2025-11-07T09:39:06.765020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 31 restaurant cities on EazyDiner.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities: 100%|█████████████████████████████████████████████████████████████████| 31/31 [01:31<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Extracted total 184 restaurants across 31 cities.\n",
      "✅ Data saved to eazydiner_all_cities.csv\n",
      "\n",
      "Sample:\n",
      "        City     Restaurant Name  \\\n",
      "0  delhi-ncr               Zing    \n",
      "1  delhi-ncr             Fifty9    \n",
      "2  delhi-ncr      Xero Courtyard   \n",
      "3  delhi-ncr      Openhouse Cafe   \n",
      "4  delhi-ncr  The Immigrant Cafe   \n",
      "\n",
      "                                       Location Rating               Deal  \\\n",
      "0       The Metropolitan Hotel & Spa, New Delhi    1.0  25% Off + 25% Off   \n",
      "1                Radisson Blu Marina, New Delhi    4.4  30% Off + 25% Off   \n",
      "2  Janpath, Connaught Place (CP), Central Delhi    4.2  50% off + 25% Off   \n",
      "3           Connaught Place (CP), Central Delhi    4.2  30% Off + 25% Off   \n",
      "4           Connaught Place (CP), Central Delhi    4.3  30% Off + 25% Off   \n",
      "\n",
      "                                           Image URL  \\\n",
      "0  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "1  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "2  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "3  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "4  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "\n",
      "                                      Restaurant URL  \n",
      "0  https://www.eazydiner.com/delhi-ncr/zing-the-m...  \n",
      "1  https://www.eazydiner.com/delhi-ncr/fifty9-rad...  \n",
      "2  https://www.eazydiner.com/delhi-ncr/xero-court...  \n",
      "3  https://www.eazydiner.com/delhi-ncr/open-house...  \n",
      "4  https://www.eazydiner.com/delhi-ncr/cafe-immig...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Multi-City Restaurant Scraper (Final Version)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas tqdm\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en\"\n",
    "CITIES_API = \"https://force.eazydiner.com/web/all-cities\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Fetch all city codes\n",
    "# --------------------------------------------------------------\n",
    "resp = requests.get(CITIES_API, headers=headers)\n",
    "if resp.status_code != 200:\n",
    "    print(\"⚠️ Failed to fetch city list.\")\n",
    "    exit()\n",
    "\n",
    "data = resp.json()\n",
    "cities_data = data.get(\"data\", {}).get(\"popular_cities\", [])\n",
    "cities = [c.get(\"code\") for c in cities_data if c.get(\"code\")]\n",
    "\n",
    "print(f\"✅ Found {len(cities)} restaurant cities on EazyDiner.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Loop through cities and scrape restaurants\n",
    "# --------------------------------------------------------------\n",
    "all_restaurants = []\n",
    "\n",
    "for city in tqdm(cities, desc=\"Scraping Cities\"):\n",
    "    city_url = f\"{BASE_URL}/{city}.json\"\n",
    "\n",
    "    try:\n",
    "        res = requests.get(city_url, headers=headers, timeout=20)\n",
    "        if res.status_code != 200:\n",
    "            print(f\"⚠️ Skipping {city} (status {res.status_code})\")\n",
    "            continue\n",
    "\n",
    "        data = res.json()\n",
    "        restaurants = (\n",
    "            data.get(\"pageProps\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"buckets\", {})\n",
    "                .get(\"popular_restaurants\", {})\n",
    "                .get(\"items\", [])\n",
    "        )\n",
    "\n",
    "        if not restaurants:\n",
    "            continue\n",
    "\n",
    "        for rest in restaurants:\n",
    "            all_restaurants.append({\n",
    "                \"City\": city,\n",
    "                \"Restaurant Name\": rest.get(\"res_name\"),\n",
    "                \"Location\": rest.get(\"location\"),\n",
    "                \"Rating\": rest.get(\"rating\"),\n",
    "                \"Deal\": rest.get(\"deal_text\"),\n",
    "                \"Image URL\": rest.get(\"image\"),\n",
    "                \"Restaurant URL\": (\n",
    "                    \"https://www.eazydiner.com/\" + rest.get(\"action_url\", \"\").lstrip(\"/\")\n",
    "                    if rest.get(\"action_url\") else None\n",
    "                )\n",
    "            })\n",
    "\n",
    "        time.sleep(1)  # polite delay\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {city}: {e}\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Save all data\n",
    "# --------------------------------------------------------------\n",
    "df = pd.DataFrame(all_restaurants)\n",
    "print(f\"\\n✅ Extracted total {len(df)} restaurants across {len(cities)} cities.\")\n",
    "df.to_csv(\"eazydiner_all_cities.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_all_cities.csv\")\n",
    "\n",
    "print(\"\\nSample:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "92d54d27-8be0-4571-a0f6-b05472493e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:41:27.256118Z",
     "iopub.status.busy": "2025-11-07T09:41:27.256118Z",
     "iopub.status.idle": "2025-11-07T09:41:32.254655Z",
     "shell.execute_reply": "2025-11-07T09:41:32.253628Z",
     "shell.execute_reply.started": "2025-11-07T09:41:27.256118Z"
    }
   },
   "outputs": [],
   "source": [
    "# inside the city loop, before appending restaurants\n",
    "page = 1\n",
    "while True:\n",
    "    page_suffix = f\"/page-{page}.json\" if page > 1 else \".json\"\n",
    "    city_url = f\"{BASE_URL}/{city}{page_suffix}\"\n",
    "\n",
    "    res = requests.get(city_url, headers=headers, timeout=20)\n",
    "    if res.status_code != 200:\n",
    "        break\n",
    "\n",
    "    data = res.json()\n",
    "    items = (\n",
    "        data.get(\"pageProps\", {})\n",
    "            .get(\"data\", {})\n",
    "            .get(\"data\", {})\n",
    "            .get(\"buckets\", {})\n",
    "            .get(\"popular_restaurants\", {})\n",
    "            .get(\"items\", [])\n",
    "    )\n",
    "\n",
    "    if not items:\n",
    "        break\n",
    "\n",
    "    # same parsing loop here\n",
    "    for rest in items:\n",
    "        all_restaurants.append({...})\n",
    "\n",
    "    page += 1\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "95034590-c033-4234-ae79-02c738e22a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:42:32.593547Z",
     "iopub.status.busy": "2025-11-07T09:42:32.592541Z",
     "iopub.status.idle": "2025-11-07T09:44:50.706498Z",
     "shell.execute_reply": "2025-11-07T09:44:50.705495Z",
     "shell.execute_reply.started": "2025-11-07T09:42:32.593547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 31 restaurant cities on EazyDiner.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:   0%|                                                                          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ delhi-ncr - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:   3%|██▏                                                               | 1/31 [00:02<01:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mumbai - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:   6%|████▎                                                             | 2/31 [00:05<01:23,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ bengaluru - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  10%|██████▍                                                           | 3/31 [00:08<01:22,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chennai - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  13%|████████▌                                                         | 4/31 [00:12<01:30,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ pune - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  16%|██████████▋                                                       | 5/31 [00:24<02:52,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ kolkata - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  19%|████████████▊                                                     | 6/31 [00:27<02:14,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ dubai - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  23%|██████████████▉                                                   | 7/31 [00:29<01:38,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ goa - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  26%|█████████████████                                                 | 8/31 [00:33<01:35,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ahmedabad - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  29%|███████████████████▏                                              | 9/31 [00:35<01:12,  3.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ jaipur - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  32%|████████████████████▉                                            | 10/31 [00:38<01:08,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ agra - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  35%|███████████████████████                                          | 11/31 [00:39<00:55,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ hyderabad - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  39%|█████████████████████████▏                                       | 12/31 [00:42<00:52,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ lucknow - Page 1 (4 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  42%|███████████████████████████▎                                     | 13/31 [00:49<01:13,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ kochi - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  45%|█████████████████████████████▎                                   | 14/31 [00:55<01:15,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ coimbatore - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  48%|███████████████████████████████▍                                 | 15/31 [01:12<02:14,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ranchi - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  52%|█████████████████████████████████▌                               | 16/31 [01:19<01:57,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ visakhapatnam - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  55%|███████████████████████████████████▋                             | 17/31 [01:21<01:28,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ patna - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  58%|█████████████████████████████████████▋                           | 18/31 [01:25<01:09,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ amritsar - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  61%|███████████████████████████████████████▊                         | 19/31 [01:26<00:50,  4.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ bhubaneswar - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  65%|█████████████████████████████████████████▉                       | 20/31 [01:28<00:38,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ indore - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  68%|████████████████████████████████████████████                     | 21/31 [01:31<00:33,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ludhiana - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  71%|██████████████████████████████████████████████▏                  | 22/31 [01:35<00:32,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mysuru - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  74%|████████████████████████████████████████████████▏                | 23/31 [01:39<00:30,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ vadodara - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  77%|██████████████████████████████████████████████████▎              | 24/31 [01:43<00:26,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ thiruvananthapuram - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  81%|████████████████████████████████████████████████████▍            | 25/31 [01:45<00:19,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ nagpur - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  84%|██████████████████████████████████████████████████████▌          | 26/31 [01:47<00:14,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ udaipur - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  87%|████████████████████████████████████████████████████████▌        | 27/31 [01:49<00:10,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ madurai - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  90%|██████████████████████████████████████████████████████████▋      | 28/31 [01:51<00:07,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ abu-dhabi - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  94%|████████████████████████████████████████████████████████████▊    | 29/31 [01:56<00:06,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ chandigarh-tricity - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities:  97%|██████████████████████████████████████████████████████████████▉  | 30/31 [02:13<00:07,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ mangalore-tricity - Page 1 (6 restaurants)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Cities: 100%|█████████████████████████████████████████████████████████████████| 31/31 [02:16<00:00,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Extracted total 184 restaurants across 31 cities.\n",
      "✅ Data saved to eazydiner_all_cities_full.csv\n",
      "\n",
      "Sample:\n",
      "        City     Restaurant Name  \\\n",
      "0  delhi-ncr               Zing    \n",
      "1  delhi-ncr             Fifty9    \n",
      "2  delhi-ncr      Xero Courtyard   \n",
      "3  delhi-ncr      Openhouse Cafe   \n",
      "4  delhi-ncr  The Immigrant Cafe   \n",
      "\n",
      "                                       Location Rating               Deal  \\\n",
      "0       The Metropolitan Hotel & Spa, New Delhi    1.0  25% Off + 25% Off   \n",
      "1                Radisson Blu Marina, New Delhi    4.4  30% Off + 25% Off   \n",
      "2  Janpath, Connaught Place (CP), Central Delhi    4.2  50% off + 25% Off   \n",
      "3           Connaught Place (CP), Central Delhi    4.2  30% Off + 25% Off   \n",
      "4           Connaught Place (CP), Central Delhi    4.3  30% Off + 25% Off   \n",
      "\n",
      "                                           Image URL  \\\n",
      "0  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "1  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "2  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "3  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "4  https://dt4l9bx31tioh.cloudfront.net/eazymedia...   \n",
      "\n",
      "                                      Restaurant URL  \n",
      "0  https://www.eazydiner.com/delhi-ncr/zing-the-m...  \n",
      "1  https://www.eazydiner.com/delhi-ncr/fifty9-rad...  \n",
      "2  https://www.eazydiner.com/delhi-ncr/xero-court...  \n",
      "3  https://www.eazydiner.com/delhi-ncr/open-house...  \n",
      "4  https://www.eazydiner.com/delhi-ncr/cafe-immig...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# EazyDiner Full India Scraper (with Pagination)\n",
    "# ==============================================================\n",
    "# Requirements:\n",
    "# pip install requests pandas tqdm\n",
    "# ==============================================================\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.eazydiner.com/_next/data/9Iz0uKJzU8-Mwrfvo8KeI/en\"\n",
    "CITIES_API = \"https://force.eazydiner.com/web/all-cities\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json, text/plain, */*\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 1: Fetch all city codes\n",
    "# --------------------------------------------------------------\n",
    "resp = requests.get(CITIES_API, headers=headers)\n",
    "if resp.status_code != 200:\n",
    "    print(\"⚠️ Failed to fetch city list.\")\n",
    "    exit()\n",
    "\n",
    "data = resp.json()\n",
    "cities_data = data.get(\"data\", {}).get(\"popular_cities\", [])\n",
    "cities = [c.get(\"code\") for c in cities_data if c.get(\"code\")]\n",
    "\n",
    "print(f\"✅ Found {len(cities)} restaurant cities on EazyDiner.\\n\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Scrape all pages for each city\n",
    "# --------------------------------------------------------------\n",
    "all_restaurants = []\n",
    "\n",
    "for city in tqdm(cities, desc=\"Scraping Cities\"):\n",
    "    page = 1\n",
    "    while True:\n",
    "        # Build URL for each page\n",
    "        page_suffix = f\"/{city}/page-{page}.json\" if page > 1 else f\"/{city}.json\"\n",
    "        city_url = f\"{BASE_URL}{page_suffix}\"\n",
    "\n",
    "        res = requests.get(city_url, headers=headers, timeout=20)\n",
    "        if res.status_code != 200:\n",
    "            break  # No more pages\n",
    "\n",
    "        data = res.json()\n",
    "        restaurants = (\n",
    "            data.get(\"pageProps\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"data\", {})\n",
    "                .get(\"buckets\", {})\n",
    "                .get(\"popular_restaurants\", {})\n",
    "                .get(\"items\", [])\n",
    "        )\n",
    "\n",
    "        if not restaurants:\n",
    "            break  # Stop if no restaurants found on this page\n",
    "\n",
    "        for rest in restaurants:\n",
    "            all_restaurants.append({\n",
    "                \"City\": city,\n",
    "                \"Restaurant Name\": rest.get(\"res_name\"),\n",
    "                \"Location\": rest.get(\"location\"),\n",
    "                \"Rating\": rest.get(\"rating\"),\n",
    "                \"Deal\": rest.get(\"deal_text\"),\n",
    "                \"Image URL\": rest.get(\"image\"),\n",
    "                \"Restaurant URL\": (\n",
    "                    \"https://www.eazydiner.com/\" + rest.get(\"action_url\", \"\").lstrip(\"/\")\n",
    "                    if rest.get(\"action_url\") else None\n",
    "                )\n",
    "            })\n",
    "\n",
    "        print(f\"✅ {city} - Page {page} ({len(restaurants)} restaurants)\")\n",
    "        page += 1\n",
    "        time.sleep(1)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Save to CSV\n",
    "# --------------------------------------------------------------\n",
    "df = pd.DataFrame(all_restaurants)\n",
    "print(f\"\\n✅ Extracted total {len(df)} restaurants across {len(cities)} cities.\")\n",
    "df.to_csv(\"eazydiner_all_cities_full.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Data saved to eazydiner_all_cities_full.csv\")\n",
    "\n",
    "print(\"\\nSample:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76597597-2191-48dd-a01c-2daeb101a90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
